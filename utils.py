import hashlib
import requests
import json
import base64

from getGlobalLogger import logger

# æ„å»ºAbsPath
def makeAbsPath(fullDict, parentFileId=0):
    _parentMapping = {} # {å­æ–‡ä»¶ID: çˆ¶æ–‡ä»¶å¤¹ID}
    # éå†æ‰€æœ‰æ–‡ä»¶å¤¹å’Œæ–‡ä»¶åˆ—è¡¨ï¼Œè®°å½•æ¯ä¸ªæ–‡ä»¶çš„çˆ¶æ–‡ä»¶å¤¹ID
    for key, value in fullDict.items():
        for item in value:
            _parentMapping[item.get("FileId")] = int(key) # item.get("ParentFileId")
    logger.debug(f"_parentMapping: {json.dumps(_parentMapping, ensure_ascii=False)}")
    # éå†æ‰€æœ‰æ–‡ä»¶å¤¹å’Œæ–‡ä»¶åˆ—è¡¨ï¼Œæ·»åŠ AbsPath
    for key, value in fullDict.items():
        for item in value:
            _absPath = str(item.get("FileId"))
            logger.debug(f"_absPath: {_absPath}")
            logger.debug(f"int(_absPath.split('/')[0]): {int(_absPath.split('/')[0])}")
            while _absPath.split("/")[0] != str(parentFileId):
                _absPath = f"{_parentMapping.get(int(_absPath.split('/')[0]))}/{_absPath}"
            item.update({"AbsPath": _absPath})
    return fullDict

# å¯¹FileIdå’ŒparentFileIdåŒ¿ååŒ–, åŒæ­¥ä¿®æ”¹AbsPath
def anonymizeId(itemsList):
    RESULT = []
    MAP_ID = {}
    count = 0
    # ç¬¬é›¶é: å¯¹ itemsList ä¸­çš„æ‰€æœ‰ item è¿›è¡Œæ’åº
    # è¿™æ˜¯ä¸ºäº†ç¡®ä¿å…·æœ‰ç›¸åŒç›®å½•å’Œæ–‡ä»¶ç»“æ„çš„é¡¹ç›®æœ€åäº§ç”Ÿçš„IDé¡ºåºä¸€è‡´(é˜²æ­¢é‡å¤)
    itemsList.sort(key=lambda x: x.get("FileName"))
    # ç¬¬ä¸€é: éå†æ‰€æœ‰çš„item.get("FileId")(åŒ…å«æ–‡ä»¶å’Œæ–‡ä»¶å¤¹), æ„å»ºæ˜ å°„è¡¨
    for item in itemsList:
        if item.get("FileId") not in MAP_ID:
            MAP_ID[item.get("FileId")] = count # åªæ˜ å°„ä¸ä¿®æ”¹æ•°æ®
            count += 1
        if item.get("parentFileId") not in MAP_ID: # æ ¹ç›®å½•åªå‡ºç°åœ¨parentFileId
            MAP_ID[item.get("parentFileId")] = count # åªæ˜ å°„ä¸ä¿®æ”¹æ•°æ®
            count += 1
    # ç¬¬äºŒé: éå†æ‰€æœ‰çš„item.get("parentFileId")å’Œitem.get("AbsPath")(åŒ…å«æ–‡ä»¶å’Œæ–‡ä»¶å¤¹), æ›¿æ¢ä¸ºåŒ¿ååŒ–åçš„ID
    for item in itemsList:
        _absPath = item.get("AbsPath").split("/")
        _absPath = [str(MAP_ID[int(i)]) for i in _absPath if len(i)]
        _absPath = "/".join(_absPath)
        RESULT.append({
            "FileId": MAP_ID[item.get("FileId")],
            "FileName": item.get("FileName"),
            "Type": item.get("Type"),
            "Size": item.get("Size"),
            "Etag": item.get("Etag"),
            "parentFileId": MAP_ID[item.get("parentFileId")],
            "AbsPath": _absPath,
        })
    return RESULT

# è¾“å…¥ä¸€æ®µæ–‡æœ¬(è¿™é‡Œæ˜¯base64åŠ å¯†åšçš„å­—ç¬¦ä¸²), è¾“å‡ºstringçš„hashå€¼
def getStringHash(text):
    return hashlib.sha256(text.encode("utf-8")).hexdigest() # è¿”å›çš„ä¸€å®šæ˜¯é•¿åº¦ä¸º64çš„å­—ç¬¦ä¸²

# æ£€æŸ¥IPæ˜¯å¦ä¸ºä¸­å›½å¤§é™†åœ°åŒº
# True: æ”¯æŒ (å¢ƒå¤–IP)
# False: ä¸æ”¯æŒ (ä¸­å›½å¤§é™†IP)
def isAvailableRegion():
    check_ip_url = "https://ipv4.ping0.cc/geo"
    response = requests.get(check_ip_url).text.replace("\n", "")
    if "ä¸­å›½" in response and not any(keyword in response for keyword in ["é¦™æ¸¯", "æ¾³é—¨", "å°æ¹¾"]):
            logger.warning(f"ä¸æ”¯æŒå½“å‰IPåœ°å€ä½¿ç”¨: {response}")
            return False
    else:
        logger.info(f"å½“å‰IPåœ°å€æ”¯æŒä½¿ç”¨: {response}")
        return True

# å†…éƒ¨å‡½æ•°ï¼šè·å–æ–‡ä»¶åå¯¹åº”çš„å›¾æ ‡
def _get_icon(file_name: str) -> str:
    if not file_name or '.' not in file_name:
        return "ğŸ“„"
 
    file_type = file_name.split('.')[-1].lower()
    if file_type in ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff', 'svg', 'webp']:
        return "ğŸ–¼ï¸"
    elif file_type in ['mp3', 'wav', 'ogg', 'dsd', 'flac', 'aac', 'wma', 'm4a', 'mpc', 'ape', 'wv', 'wvx', 'dff', 'dsf', 'm4p']:
        return "ğŸµ"
    elif file_type in ['mp4', 'mkv', 'avi', 'mov', 'wmv', 'flv', 'webm', '3gp', 'm4v', 'ogv', 'asf', 'mts', 'm2ts', 'ts']:
        return "ğŸ¥"
    elif file_type in ['zip', 'rar', '7z', 'tar', 'gz', 'bz2']:
        return "ğŸ“¦"
    else:
        return "ğŸ“„"
 
# ç”Ÿæˆç›®å½•æ ‘
# æœ¬å‡½æ•°ç”± Gemini 2.5 Pro ç”Ÿæˆ
def generateContentTree(b64_data_str: str) -> dict:
    # 0. è§£ç  base64 æ•°æ®
    try:
        all_items_list = json.loads(base64.urlsafe_b64decode(b64_data_str).decode("utf-8"))
    except Exception as e:
        logger.error(f"generateContentTree: è§£ç  base64 æ•°æ®å¤±è´¥: {e}", exc_info=True)
        return {"isFinish": False, "message": f"é”™è¯¯: {e}"}
 
    # 1. æ„å»ºèŠ‚ç‚¹æ˜ å°„è¡¨ (FileId -> item_data) å¹¶åˆå§‹åŒ–å­èŠ‚ç‚¹åˆ—è¡¨
    nodes = {}
    for item_dict in all_items_list:
        item = item_dict.copy()
        item['children'] = []
        nodes[item['FileId']] = item
 
    # 2. æ„å»ºæ ‘å½¢ç»“æ„
    root_items = []
    all_file_ids_in_data = set(nodes.keys())
 
    for item_id, item_data in nodes.items():
        parent_id = item_data.get('parentFileId')
        if parent_id is not None and parent_id in nodes:
            nodes[parent_id]['children'].append(item_data)
        elif parent_id not in all_file_ids_in_data or parent_id is None: # å¤„ç†æ ¹é¡¹ç›®æˆ–çˆ¶é¡¹ä¸åœ¨å½“å‰åˆ—è¡¨ä¸­çš„æƒ…å†µ
            root_items.append(item_data)
 
    # 3. æ’åº: å…ˆæŒ‰ç±»å‹(æ–‡ä»¶å¤¹ä¼˜å…ˆ)ï¼Œå†æŒ‰æ–‡ä»¶å
    for node in nodes.values():
        if node['children']:
            # ç¡®ä¿ Type å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸ºæ–‡ä»¶ç±»å‹ (0)
            node['children'].sort(key=lambda x: (x.get('Type', 0) != 1, x['FileName']))
    
    root_items.sort(key=lambda x: (x.get('Type', 0) != 1, x['FileName']))
 
    # 4. é€’å½’ç”Ÿæˆæ ‘å½¢å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ç›®æ˜¯ [è¡Œæ–‡æœ¬, FileId]
    tree_lines_with_ids = [] 
 
    def generate_lines_for_list_recursive(item_list, base_prefix):
        num_items = len(item_list)
        for i, item_data in enumerate(item_list):
            is_last = (i == num_items - 1)
            # ç¡®ä¿ Type å­˜åœ¨
            icon = "ğŸ“‚" if item_data.get('Type') == 1 else _get_icon(item_data['FileName'])
            connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            line_text = f"{base_prefix}{connector}{icon} {item_data['FileName']}"
            tree_lines_with_ids.append([line_text, item_data['FileId']]) # å­˜å‚¨è¡Œæ–‡æœ¬å’ŒFileId
            
            children_prefix = base_prefix + ("    " if is_last else "â”‚   ")
            if item_data['children']:
                generate_lines_for_list_recursive(item_data['children'], children_prefix)
 
    # 5. ä»æ ¹èŠ‚ç‚¹å¼€å§‹ç”Ÿæˆ
    num_root_items = len(root_items)
    for i, root_item_data in enumerate(root_items):
        # ç¡®ä¿ Type å­˜åœ¨
        icon = "ğŸ“‚" if root_item_data.get('Type') == 1 else _get_icon(root_item_data['FileName'])
        root_line_text = f"{icon} {root_item_data['FileName']}"
        tree_lines_with_ids.append([root_line_text, root_item_data['FileId']])
        
        if root_item_data['children']:
            generate_lines_for_list_recursive(root_item_data['children'], "") 
                                                                    
    logger.debug(f"generateContentTree: ç”Ÿæˆçš„ç›®å½•æ ‘æ¡ç›®æ•°: {len(tree_lines_with_ids)}")
    return {"isFinish": True, "message": tree_lines_with_ids}

# å°† etag è½¬æ¢ä¸º 123FastLink ä½¿ç”¨ Base62 åŠ å¯†åçš„å­—ç¬¦ä¸² 
def encryptEtagTo123FastLinkEtag(etag: str) -> str:
    _BASE62_CHARS = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
    
    # å°†åå…­è¿›åˆ¶å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°
    big_int_value = int(etag, 16)

    # å°†æ•´æ•°è½¬æ¢ä¸º Base62 å­—ç¬¦ä¸²
    if big_int_value == 0:
        return _BASE62_CHARS[0]
    base62_chars_list = []
    n = big_int_value
    while n > 0:
        remainder = n % 62
        base62_chars_list.append(_BASE62_CHARS[remainder])
        n = n // 62
    
    # åè½¬åˆ—è¡¨å¹¶è¿æ¥æˆå­—ç¬¦ä¸²
    return "".join(reversed(base62_chars_list))

# å°† 123FastLink ä½¿ç”¨ Base62 åŠ å¯†åçš„å­—ç¬¦ä¸²è½¬æ¢ä¸º etag
def decrypt123FastLinkEtagToEtag(encrypted_etag: str) -> str:
    _BASE62_CHARS = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"

    # å°† Base62 å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°
    big_int_value = 0
    for char in encrypted_etag:
        big_int_value = big_int_value * 62 + _BASE62_CHARS.index(char)

    # å°†æ•´æ•°è½¬æ¢ä¸ºåå…­è¿›åˆ¶å­—ç¬¦ä¸²
    hex_str = hex(big_int_value)[2:]

    # ç¡®ä¿åå…­è¿›åˆ¶å­—ç¬¦ä¸²é•¿åº¦ä¸º 32
    if len(hex_str) < 32:
        hex_str = "0" * (32 - len(hex_str)) + hex_str

    return hex_str

# å°†æœ¬é¡¹ç›®çš„åˆ†äº«ç è½¬æ¢ä¸º 123FastLink æ ¼å¼çš„ json
def transformShareCodeTo123FastLinkJson(rootFolderName, shareCode):
    # è§£æ base64 æ•°æ®
    data = base64.urlsafe_b64decode(shareCode).decode("utf-8")
    data = json.loads(data)
    
    # å­˜å‚¨æœ€ç»ˆè¾“å‡º
    OUTPUT = {
        "scriptVersion": "114514",
        "exportVersion": "114514",
        "usesBase62EtagsInExport": True,
        "commonPath": f"{rootFolderName}/",
        "files": [] # [{"path": ..., "size": ..., "etag", ...}, ...]
    }

    NAME_MAP = {} # {FileId: FileName}
    # ç¬¬ä¸€è½®:
    # éå†æ¯æ¡æ•°æ®, è®°è½½æ¯ä¸ª FileId å¯¹åº”çš„ FileName
    for item in data:
        NAME_MAP[str(item["FileId"])] = item["FileName"] # è¿™é‡Œå§FileIdç»Ÿä¸€ä¸ºstringæ ¼å¼é˜²æ­¢æŠ¥é”™

    # ç¬¬äºŒè½®:
    # éå†æ¯æ¡æ•°æ®, æ„å»ºå®Œæ•´ç›®å½•
    for item in data:
        # è·³è¿‡æ–‡ä»¶å¤¹
        if item["Type"] == 1:
            continue

        path = "/".join([NAME_MAP[id] for id in item['AbsPath'].split('/')])
        OUTPUT['files'].append({
            "path": path,
            "size": item["Size"],
            "etag": encryptEtagTo123FastLinkEtag(item["Etag"]),
        })
        
    return OUTPUT

def transform123FastLinkJsonToShareCode(json_dict):
    if not json_dict["usesBase62EtagsInExport"]: # usesBase62EtagsInExportå¿…é¡»ä¸ºtrue
        raise Exception("æœªçŸ¥æ ¼å¼")
    multiple_root_folder_flag = not len(json_dict["commonPath"]) # å¦‚æœcommonPathä¸ºç©º, åˆ™multiple_root_folder_flagä¸ºtrue
    
    # æœ€ç»ˆè¾“å‡º: [{"rootFolderName": ..., "shareCode": ...}, ...]
    OUTPUT = [] # å¦‚æœmultiple_root_folder_flagä¸ºtrue, åˆ™ä¼šé’ˆå¯¹å¤šä¸ªæ–‡ä»¶å¤¹ç”Ÿæˆå¤šä¸ªåˆ†äº«ç 
    # ç”¨äºå­˜å‚¨IDæ˜ å°„è¡¨
    ALL_MAP = {} # å­˜å‚¨ {depth(int): {FileName(string): FileId(int)}}
    # ç”¨äºå­˜å‚¨æ·»åŠ è¿‡çš„æ–‡ä»¶å¤¹path
    ADDED_PATH = set()

    # å…ˆä¸è€ƒè™‘å¤šæ–‡ä»¶å¤¹, è¿™é‡Œå­˜å‚¨æ‰€æœ‰çš„æ–‡ä»¶/æ–‡ä»¶å¤¹
    # æ ¼å¼å¦‚ä¸‹
    # {
    #     "FileId": int,
    #     "FileName": string,
    #     "Type": int, # 0: æ–‡ä»¶, 1: æ–‡ä»¶å¤¹
    #     "Size": int,
    #     "Etag": string,
    #     "parentFileId": int,
    #     "AbsPath": string
    # }
    ALL_ITEMS = []

    # æ³¨: ç”±äºå†™åˆ°è¿™é‡Œè„‘å­å¤ªæ™•äº†, æ‰€ä»¥è¿™é‡Œç›´æ¥æš´åŠ›ç®—æ³•æ— è„‘è§£å†³
    
    root_folder_id = 0 # è¿™é‡Œè®©æ ¹æ–‡ä»¶å¤¹çš„FileIdä¸º0
    id_count = 1 # å…¶ä»–æ–‡ä»¶/æ–‡ä»¶å¤¹æ’åºä»1å¼€å§‹

    # ç¬¬ä¸€è½®: 
    # é¦–å…ˆè€ƒè™‘å•æ–‡ä»¶æƒ…å†µ: å¦‚æœè·¯å¾„æ²¡æœ‰æ–œæ , åˆ™ä¸ºå•æ–‡ä»¶, è·å–æ–‡ä»¶ååå•ç‹¬å­˜å‚¨
    if multiple_root_folder_flag:
        _temp = []
        for item in json_dict["files"]:
            path = item["path"]
            if "/" not in path:
                # å¯¹å•ä¸ªæ–‡ä»¶ç›´æ¥æ·»åŠ 
                _item_json = [{
                    "FileId": 1,
                    "FileName": path,
                    "Type": 0,
                    "Size": item["size"],
                    "Etag": decrypt123FastLinkEtagToEtag(item["etag"]),
                    "parentFileId": root_folder_id, 
                    "AbsPath": "1"
                }]
                # åŒ¿ååŒ–
                _item_json = anonymizeId(_item_json)
                OUTPUT.append({
                    "rootFolderName": path,
                    "shareCode": base64.urlsafe_b64encode(json.dumps(_item_json).encode("utf-8")).decode("utf-8") 
                })
            else:
                _temp.append(item)
        json_dict["files"] = _temp
            
    # ç¬¬äºŒè½®:
    # éå†æ‰€æœ‰æ–‡ä»¶, æ„å»ºæ˜ å°„è¡¨
    for item in json_dict["files"]:
        path = item["path"].split("/")
        # path çš„æœ€åä¸€é¡¹ä¸€å®šæ˜¯æ–‡ä»¶å
        _folderNames = path[:-1]
        _fileName = path[-1]
        _current_depth = len(_folderNames)
        # æ£€æŸ¥å½“å‰ALL_MAPæ˜¯å¦æœ‰å½“å‰æ·±åº¦çš„dict
        for i in range(_current_depth+1):
            if i not in ALL_MAP:
                ALL_MAP[i] = {}
        # æ·»åŠ æ–‡ä»¶
        if _fileName not in ALL_MAP[_current_depth]:
            ALL_MAP[_current_depth][_fileName] = id_count
            id_count += 1
        # æ·»åŠ æ–‡ä»¶å¤¹
        for _depth, _folderName in enumerate(_folderNames):
            if _folderName not in ALL_MAP[_depth]:
                ALL_MAP[_depth][_folderName] = id_count
                id_count += 1
    # ç¬¬ä¸‰è½®:
    # éå†æ‰€æœ‰æ–‡ä»¶, æŠŠæ‰€æœ‰é¡¹æ·»åŠ åˆ°ALL_ITEMSä¸­
    for item in json_dict["files"]:
        path = item["path"].split("/")
        # path çš„æœ€åä¸€é¡¹ä¸€å®šæ˜¯æ–‡ä»¶å
        _folderNames = path[:-1]
        _fileName = path[-1]
        _current_depth = len(_folderNames)
        _parentFileId = root_folder_id if _current_depth == 0 else ALL_MAP[_current_depth - 1][_folderNames[-1]]
        _AbsPath = "/".join([str(ALL_MAP[i][j]) for i, j in enumerate(_folderNames)]) + "/" + str(ALL_MAP[_current_depth][_fileName])
        # æ·»åŠ æ–‡ä»¶
        ALL_ITEMS.append({
            "FileId": ALL_MAP[_current_depth][_fileName],
            "FileName": _fileName,
            "Type": 0,
            "Size": item["size"],
            "Etag": decrypt123FastLinkEtagToEtag(item["etag"]),
            "parentFileId": _parentFileId,
            "AbsPath": _AbsPath
        })
        # æ·»åŠ æ–‡ä»¶å¤¹
        for _current_depth in range(len(_folderNames)):
            _folderName = _folderNames[_current_depth]
            _AbsPath = "/".join([str(ALL_MAP[i][j]) for i, j in enumerate(_folderNames[:_current_depth + 1])])
            if _AbsPath not in ADDED_PATH:
                ADDED_PATH.add(_AbsPath)
                ALL_ITEMS.append({
                    "FileId": ALL_MAP[_current_depth][_folderName],
                    "FileName": _folderName,
                    "Type": 1,
                    "Size": 0,
                    "Etag": "",
                    "parentFileId": root_folder_id if _current_depth == 0 else ALL_MAP[_current_depth - 1][_folderNames[_current_depth - 1]],
                    "AbsPath": _AbsPath   
                })

    # ç¬¬å››è½®:
    # åˆ¤æ–­æ˜¯å¦ä¸ºå¤šæ–‡ä»¶å¤¹
    if multiple_root_folder_flag:
        # å¯¹äºå¤šæ–‡ä»¶å¤¹æƒ…å†µ: å¦‚æœ str(item.get("FileId")) == item.get("AbsPath"), åˆ™ä¸ºæ ¹æ–‡ä»¶å¤¹
        all_root_folders_files = {} # å­˜å‚¨ {rootFolderId(int): files(list)}
        all_root_folders_names = {} # å­˜å‚¨ {rootFolderId(int): rootFolderName(string)}
        # ç¬¬äº”è½®:
        # éå†æ‰€æœ‰æ–‡ä»¶, å¯»æ‰¾æ ¹æ–‡ä»¶å¤¹
        for item in ALL_ITEMS:
            if str(item.get("FileId")) == item.get("AbsPath"):
                all_root_folders_files[int(item.get("FileId"))] = []
                all_root_folders_names[int(item.get("FileId"))] = item.get("FileName")
        # ç¬¬å…­è½®:
        # éå†æ‰€æœ‰æ–‡ä»¶, æŠŠæ‰€æœ‰é¡¹æ·»åŠ åˆ°æ ¹æ–‡ä»¶å¤¹ä¸­
        for item in ALL_ITEMS:
            # å¦‚æœæ˜¯æ ¹ç›®å½•, è’‹parentFileIdæ”¹ä¸º-1
            if item.get("FileId") in all_root_folders_files.keys():
                # print(item.get("FileId"), item.get("FileName"))
                item["parentFileId"] = -1
            root_folder_id = int(item.get("AbsPath").split("/")[0])
            all_root_folders_files[root_folder_id].append(item)
        # åŒ¿ååŒ–
        for root_folder_id, root_folder_files in all_root_folders_files.items():
            item = anonymizeId(root_folder_files)
            OUTPUT.append({
                "rootFolderName": all_root_folders_names[root_folder_id],
                "shareCode": base64.urlsafe_b64encode(json.dumps(item, ensure_ascii=False).encode("utf-8")).decode("utf-8")
            })
    else:
        # å¯¹äºå•æ–‡ä»¶å¤¹æƒ…å†µ: æ·»åŠ ä¸€ä¸ªID=0çš„æ–‡ä»¶å¤¹(commonPath.replace("\")), å¹¶ç»™æ‰€æœ‰AbsPathæ·»åŠ 0
        for item in ALL_ITEMS:
            item["AbsPath"] = "0" + item["AbsPath"]
        ALL_ITEMS.append({
            "FileId": 0,
            "FileName": json_dict["commonPath"].replace("/", "").replace("\\", ""),
            "Type": 1,
            "Size": 0,
            "Etag": "",
            "parentFileId": -1,
            "AbsPath": "0"
        })
        # åŒ¿ååŒ–
        ALL_ITEMS = anonymizeId(ALL_ITEMS)
        # base64åŠ å¯†
        OUTPUT.append({
            "rootFolderName": json_dict["commonPath"].replace("/", "").replace("\\", ""),
            "shareCode": base64.urlsafe_b64encode(json.dumps(ALL_ITEMS, ensure_ascii=False).encode("utf-8")).decode("utf-8") 
        })

    return OUTPUT

def getSearchText(b64data, rootFolderName):
    result = rootFolderName + " "
    data = base64.urlsafe_b64decode(b64data).decode("utf-8")
    data = json.loads(data)
    for item in data:
        result += item["FileName"]
        result += " "
    return result